{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Afiaka DALL-E Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/DALL-E/blob/main/Afiaka_DALL_E_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0lST-nhvubF"
      },
      "source": [
        "### Colab by mega b#6696\n",
        "\n",
        "##### [Original Model](https://github.com/lucidrains/DALLE-pytorch/issues/319) & [Colab](https://github.com/afiaka87/dalle-pytorch-pretrained) simplified.\n",
        "\n",
        "---\n",
        "\n",
        "#### Join the [Dall-E PyTorch Discord server](https://discord.gg/dall-e) to help with recreating Dall-E!"
      ],
      "id": "E0lST-nhvubF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS7ZTHTy3hM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "f49460b8-9e28-4fea-cc2f-9556b6da74af"
      },
      "source": [
        "#@markdown # **1** Setup, run this once.\n",
        "from IPython.display import clear_output\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "eval_js('google.colab.output.setIframeHeight(\"250\")')\n",
        "\n",
        "!nvidia-smi\n",
        "!pip install git+https://github.com/afiaka87/CLIP.git\n",
        "!pip install taming-transformers\n",
        "!pip install dalle-pytorch\n",
        "!pip install tokenizers\n",
        "!pip install ftfy\n",
        "!pip install regex\n",
        "!pip install tqdm\n",
        "!git clone https://github.com/afiaka87/dalle-pytorch-pretrained.git\n",
        "!pip install wandb\n",
        "%cd dalle-pytorch-pretrained\n",
        "\n",
        "clear_output()\n",
        "\n",
        "eval_js('google.colab.output.setIframeHeight(\"250\")')\n",
        "\n",
        "#!wget --no-clobber https://www.dropbox.com/s/hl5hyzhyal3vfye/dalle_iconic_butterfly_149.pt\n",
        "%pip install tokenizers\n",
        "from tokenizers import Tokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = Tokenizer.from_file(\"/content/dalle-pytorch-pretrained/cc12m_tokenizer.json\")\n",
        "\n",
        "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
        "\n",
        "def tokenize(texts, context_length = 256, add_start = False, add_end = False, truncate_text = False):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    sot_tokens = tokenizer.encode(\"<|startoftext|>\").ids if add_start else []\n",
        "    eot_tokens = tokenizer.encode(\"<|endoftext|>\").ids if add_end else []\n",
        "    all_tokens = [sot_tokens + tokenizer.encode(text).ids + eot_tokens for text in texts]\n",
        "    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
        "\n",
        "    for i, tokens in enumerate(all_tokens):\n",
        "        if len(tokens) > context_length:\n",
        "            if truncate_text:\n",
        "                tokens = tokens[:context_length]\n",
        "            else:\n",
        "                raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
        "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
        "\n",
        "    return result\n",
        "\n",
        "!wget --no-clobber <dropbox_url>\n",
        "\n",
        "%pip install gpustat\n",
        "!git clone https://github.com/lucidrains/DALLE-pytorch\n",
        "%cd ./DALLE-pytorch/\n",
        "!python3 setup.py install\n",
        "!sudo apt-get -y install llvm-9-dev cmake\n",
        "!git clone https://github.com/microsoft/DeepSpeed.git /tmp/Deepspeed\n",
        "%cd /tmp/Deepspeed\n",
        "!DS_BUILD_SPARSE_ATTN=1 ./install.sh -r\n",
        "\n",
        "!pip install deepspeed\n",
        "\n",
        "%cd /content/\n",
        "!apt-get install pv\n",
        "!apt-get install jq\n",
        "!wget https://raw.githubusercontent.com/tonikelope/megadown/master/megadown -O megadown.sh\n",
        "!chmod 755 megadown.sh\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Finished, move onto the next cell.\")"
      ],
      "id": "rS7ZTHTy3hM-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished, move onto the next cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pl8ovcl5T8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "d63c08ef-f6d6-4a3d-92c7-292f9e5a57af"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "eval_js('google.colab.output.setIframeHeight(\"500\")')\n",
        "\n",
        "#@markdown # **2** Download the [Afiaka Dall-E Blogpost Model.](https://github.com/lucidrains/DALLE-pytorch/issues/319)\n",
        "\n",
        "!gdown --id 1-F36hOY-6AkuLq_pFfsm97qHJhbnb9VA -O dalle_checkpoint.pt\n",
        "\n",
        "clear_output()\n",
        "\n",
        "!mkdir -p ~/.cache/dalle;\n",
        "\n",
        "!gdown --id 1-PnwaG_dCRGQFspBRrFTl0EjYWtSqFrY -O vqgan.1024.model.ckpt\n",
        "\n",
        "!gdown --id 1-SXD1weAVIPkMp2fHfhmsc7iUpjhzNsy -O vqgan.1024.config.yml\n",
        "\n",
        "!cp \"vqgan.1024.model.ckpt\" ~/.cache/dalle;\n",
        "!cp \"vqgan.1024.config.yml\" ~/.cache/dalle;\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Finished downloading the selected model.\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random"
      ],
      "id": "2Pl8ovcl5T8h",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished downloading the selected model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOi-8QVhuyK"
      },
      "source": [
        "# **For inference,** you will have to download and look through [these captions](https://github-repository-files.githubusercontent.com/327113050/6719423?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210626%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210626T021338Z&X-Amz-Expires=300&X-Amz-Signature=b12fa27c42351be2967c358ea0cb57a2bd885b694d47505f507aff01fcda8441&X-Amz-SignedHeaders=host&actor_id=43943237&key_id=0&repo_id=327113050&response-content-disposition=attachment%3Bfilename%3Dsample_12800.txt.gz&response-content-type=application%2Fx-gzip) to get an understanding of what to prompt: "
      ],
      "id": "OIOi-8QVhuyK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "682c5804-5f97-469f-8cf1-1cc8356591b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8586abe8-dc56-42fb-d18a-97c46dfe1b00"
      },
      "source": [
        "#@markdown # **3** Try out the model.\n",
        "#@markdown #### Results will be saved in the outputs directory. Refresh (right click the folder -> refresh) if you dont see the result inside the folder.\n",
        "eval_js('google.colab.output.setIframeHeight(\"1000\")')\n",
        "\n",
        "checkpoint_path = \"/content/dalle_checkpoint.pt\"\n",
        "\n",
        "text = \"a female mannequin dressed in a blue jacket and red skirt\" #@param {type:\"string\"}\n",
        "\n",
        "generate_16_images = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_images = 8\n",
        "batch_size = 8\n",
        "\n",
        "if generate_16_images:\n",
        "  num_images = 16\n",
        "  batch_size = 16\n",
        "\n",
        "\n",
        "text_cleaned = text.replace(\" \", \"_\")\n",
        "_folder = f\"/content/outputs/{text_cleaned}/\"\n",
        "\n",
        "!python /content/dalle-pytorch-pretrained/DALLE-pytorch/generate.py --dalle_path=$checkpoint_path --taming --text=\"$text\" --num_images=$num_images --batch_size=$batch_size --outputs_dir=\"$_folder\"; wait;\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Finished generating images, attempting to display results...\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "final = text_cleaned[:100]\n",
        "\n",
        "text_cleaned = text.replace(\" \", \"_\")\n",
        "output_dir = f\"/content/outputs/{text_cleaned}/{final}/\" \n",
        "images = []\n",
        "\n",
        "for img_path in glob.glob(f'{output_dir}*.jpg'):\n",
        "    images.append(mpimg.imread(img_path))\n",
        "\n",
        "plt.figure(figsize=(32,32))\n",
        "\n",
        "if generate_16_images:\n",
        "  plt.figure(figsize=(64,64))\n",
        "\n",
        "columns = 4\n",
        "for i, image in enumerate(images):\n",
        "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "    plt.imshow(image)\n"
      ],
      "id": "682c5804-5f97-469f-8cf1-1cc8356591b8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished generating images, attempting to display results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2304x2304 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}